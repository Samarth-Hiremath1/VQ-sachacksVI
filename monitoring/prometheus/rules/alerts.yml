groups:
  - name: coaching_platform_alerts
    rules:
      # Service Health Alerts
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "Service {{ $labels.job }} has been down for more than 1 minute."

      # Database Alerts
      - alert: PostgreSQLDown
        expr: up{job="postgres"} == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL database is not responding."

      # Redis Alerts
      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Redis is down"
          description: "Redis cache service is not responding."

      # Storage Alerts
      - alert: MinIODown
        expr: up{job="minio"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "MinIO storage is down"
          description: "MinIO S3-compatible storage service is not responding."

      # ML Service Alerts
      - alert: MLServiceDown
        expr: up{job=~"pytorch-service|tensorflow-service"} == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "ML Service {{ $labels.job }} is down"
          description: "Machine Learning service {{ $labels.job }} has been down for more than 2 minutes."

      # API Performance Alerts
      - alert: HighAPILatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="fastapi-backend"}[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High API latency detected"
          description: "95th percentile latency is above 2 seconds for more than 5 minutes."

      # Error Rate Alerts
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is above 10% for more than 5 minutes."

      # Resource Usage Alerts
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is above 90% for more than 5 minutes."

      # MLflow Alerts
      - alert: MLflowDown
        expr: up{job="mlflow"} == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "MLflow tracking server is down"
          description: "MLflow experiment tracking service is not responding."

      # Airflow Alerts
      - alert: AirflowDown
        expr: up{job="airflow"} == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Airflow is down"
          description: "Airflow workflow orchestration service is not responding."